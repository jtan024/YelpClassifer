{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyparsing.py:943: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  collections.MutableMapping.register(ParseResults)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyparsing.py:3245: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  elif isinstance( exprs, collections.Iterable ):\n",
      "Skipping line 27292: unexpected end of data\n"
     ]
    }
   ],
   "source": [
    "# Run in terminal or command prompt\n",
    "# python3 -m spacy download en\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from spacy.lang.en import English\n",
    "%matplotlib inline\n",
    "df = pd.read_csv('reviews_100k.csv', error_bad_lines=False, engine='python')\n",
    "df = df.drop(columns=['user_id', 'review_id', 'votes.cool', 'business_id', 'votes.funny', 'stars', 'votes.useful', 'date', 'type'], axis=1)\n",
    "df = df.dropna(subset=['text'])\n",
    "data = df.text.values.tolist()# Remove Emails\n",
    "data = [re.sub(r'\\S*@\\S*\\s?', '', sent) for sent in data]# Remove new line characters\n",
    "data = [re.sub(r'\\s+', ' ', sent) for sent in data]# Remove distracting single quotes\n",
    "data = [re.sub(r\"\\'\", \"\", sent) for sent in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['institution walk seem throwback year booth selection food speciality hoagie vote area year year order burger patty cook ingredient alternative subway road', 'customer miss machine use place steep tradition']\n",
      "LatentDirichletAllocation(learning_method='online', n_components=20, n_jobs=-1,\n",
      "                          random_state=100)\n"
     ]
    }
   ],
   "source": [
    "##pprint(data[:1])\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "data_words = list(sent_to_words(data))\n",
    "##print(data_words[:1])\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']): #'NOUN', 'ADJ', 'VERB', 'ADV'\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out\n",
    "# Initialize spacy ‘en’ model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python -m spacy download en\n",
    "# Initialize spacy ‘en’ model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'VERB']) #select noun and verb\n",
    "print(data_lemmatized[:2])\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,\n",
    "# minimum reqd occurences of a word \n",
    "                             stop_words='english',             \n",
    "# remove stop words\n",
    "                             lowercase=True,                   \n",
    "# convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  \n",
    "# num chars > 3\n",
    "                             # max_features=50000,             \n",
    "# max number of uniq words    \n",
    "                            )\n",
    "                             \n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)\n",
    "                             \n",
    "                             # Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=20,               # Number of topics\n",
    "                                      max_iter=10,               \n",
    "# Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          \n",
    "# Random state\n",
    "                                      batch_size=128,            \n",
    "# n docs in each learning iter\n",
    "                                      evaluate_every = -1,       \n",
    "# compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               \n",
    "# Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -6204889.081096731\n",
      "Perplexity:  1102.4702701673116\n",
      "{'batch_size': 128,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'online',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 10,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 20,\n",
      " 'n_jobs': -1,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': 100,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>price</td>\n",
       "      <td>service</td>\n",
       "      <td>make</td>\n",
       "      <td>quality</td>\n",
       "      <td>try</td>\n",
       "      <td>dress</td>\n",
       "      <td>wife</td>\n",
       "      <td>choose</td>\n",
       "      <td>wine</td>\n",
       "      <td>think</td>\n",
       "      <td>place</td>\n",
       "      <td>size</td>\n",
       "      <td>look</td>\n",
       "      <td>menu</td>\n",
       "      <td>course</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>burger</td>\n",
       "      <td>fry</td>\n",
       "      <td>bbq</td>\n",
       "      <td>gate</td>\n",
       "      <td>ingredient</td>\n",
       "      <td>ring</td>\n",
       "      <td>mert</td>\n",
       "      <td>spring</td>\n",
       "      <td>booth</td>\n",
       "      <td>taco</td>\n",
       "      <td>meatball</td>\n",
       "      <td>hope</td>\n",
       "      <td>pack</td>\n",
       "      <td>bone</td>\n",
       "      <td>weather</td>\n",
       "      <td>meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>hotel</td>\n",
       "      <td>stay</td>\n",
       "      <td>flight</td>\n",
       "      <td>walk</td>\n",
       "      <td>night</td>\n",
       "      <td>downtown</td>\n",
       "      <td>place</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>travel</td>\n",
       "      <td>check</td>\n",
       "      <td>chair</td>\n",
       "      <td>street</td>\n",
       "      <td>terminal</td>\n",
       "      <td>option</td>\n",
       "      <td>security</td>\n",
       "      <td>location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>spend</td>\n",
       "      <td>floor</td>\n",
       "      <td>card</td>\n",
       "      <td>offer</td>\n",
       "      <td>look</td>\n",
       "      <td>lot</td>\n",
       "      <td>thing</td>\n",
       "      <td>variety</td>\n",
       "      <td>place</td>\n",
       "      <td>credit</td>\n",
       "      <td>bag</td>\n",
       "      <td>window</td>\n",
       "      <td>locate</td>\n",
       "      <td>appreciate</td>\n",
       "      <td>house</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>store</td>\n",
       "      <td>shop</td>\n",
       "      <td>buy</td>\n",
       "      <td>selection</td>\n",
       "      <td>item</td>\n",
       "      <td>bed</td>\n",
       "      <td>purchase</td>\n",
       "      <td>product</td>\n",
       "      <td>sale</td>\n",
       "      <td>market</td>\n",
       "      <td>section</td>\n",
       "      <td>grocery</td>\n",
       "      <td>book</td>\n",
       "      <td>help</td>\n",
       "      <td>need</td>\n",
       "      <td>shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>hair</td>\n",
       "      <td>salon</td>\n",
       "      <td>color</td>\n",
       "      <td>picture</td>\n",
       "      <td>hate</td>\n",
       "      <td>stylist</td>\n",
       "      <td>haircut</td>\n",
       "      <td>receive</td>\n",
       "      <td>discover</td>\n",
       "      <td>experience</td>\n",
       "      <td>listen</td>\n",
       "      <td>elevator</td>\n",
       "      <td>com</td>\n",
       "      <td>band</td>\n",
       "      <td>reach</td>\n",
       "      <td>hair salon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>room</td>\n",
       "      <td>staff</td>\n",
       "      <td>area</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>work</td>\n",
       "      <td>class</td>\n",
       "      <td>center</td>\n",
       "      <td>location</td>\n",
       "      <td>water</td>\n",
       "      <td>pool</td>\n",
       "      <td>machine</td>\n",
       "      <td>desk</td>\n",
       "      <td>use</td>\n",
       "      <td>day</td>\n",
       "      <td>stay</td>\n",
       "      <td>cleaniness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>place</td>\n",
       "      <td>time</td>\n",
       "      <td>make</td>\n",
       "      <td>know</td>\n",
       "      <td>love</td>\n",
       "      <td>year</td>\n",
       "      <td>try</td>\n",
       "      <td>look</td>\n",
       "      <td>want</td>\n",
       "      <td>come</td>\n",
       "      <td>say</td>\n",
       "      <td>feel</td>\n",
       "      <td>think</td>\n",
       "      <td>people</td>\n",
       "      <td>visit</td>\n",
       "      <td>communciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>pizza</td>\n",
       "      <td>sandwich</td>\n",
       "      <td>cheese</td>\n",
       "      <td>steak</td>\n",
       "      <td>order</td>\n",
       "      <td>beef</td>\n",
       "      <td>place</td>\n",
       "      <td>eat</td>\n",
       "      <td>fry</td>\n",
       "      <td>slice</td>\n",
       "      <td>sauce</td>\n",
       "      <td>crust</td>\n",
       "      <td>delivery</td>\n",
       "      <td>meat</td>\n",
       "      <td>wing</td>\n",
       "      <td>fast food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>reservation</td>\n",
       "      <td>tomato</td>\n",
       "      <td>city</td>\n",
       "      <td>buffet</td>\n",
       "      <td>wrap</td>\n",
       "      <td>joint</td>\n",
       "      <td>pickle</td>\n",
       "      <td>lettuce</td>\n",
       "      <td>highlight</td>\n",
       "      <td>concourse</td>\n",
       "      <td>platter</td>\n",
       "      <td>pad</td>\n",
       "      <td>mustard</td>\n",
       "      <td>stomach</td>\n",
       "      <td>weekend</td>\n",
       "      <td>american sandwich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 10</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>kid</td>\n",
       "      <td>pancake</td>\n",
       "      <td>ride</td>\n",
       "      <td>egg</td>\n",
       "      <td>level</td>\n",
       "      <td>club</td>\n",
       "      <td>year</td>\n",
       "      <td>brunch</td>\n",
       "      <td>team</td>\n",
       "      <td>art</td>\n",
       "      <td>toast</td>\n",
       "      <td>museum</td>\n",
       "      <td>schedule</td>\n",
       "      <td>child</td>\n",
       "      <td>american breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 11</th>\n",
       "      <td>food</td>\n",
       "      <td>salmon</td>\n",
       "      <td>star</td>\n",
       "      <td>fly</td>\n",
       "      <td>service</td>\n",
       "      <td>night</td>\n",
       "      <td>movie</td>\n",
       "      <td>rib</td>\n",
       "      <td>dining</td>\n",
       "      <td>sushi</td>\n",
       "      <td>place</td>\n",
       "      <td>miss</td>\n",
       "      <td>clt</td>\n",
       "      <td>girl</td>\n",
       "      <td>date</td>\n",
       "      <td>dinner plates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 12</th>\n",
       "      <td>coffee</td>\n",
       "      <td>tea</td>\n",
       "      <td>love</td>\n",
       "      <td>seating</td>\n",
       "      <td>place</td>\n",
       "      <td>sub</td>\n",
       "      <td>cup</td>\n",
       "      <td>choice</td>\n",
       "      <td>layover</td>\n",
       "      <td>lot</td>\n",
       "      <td>starbuck</td>\n",
       "      <td>hang</td>\n",
       "      <td>standard</td>\n",
       "      <td>lol</td>\n",
       "      <td>drink</td>\n",
       "      <td>morning drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 13</th>\n",
       "      <td>cake</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>birthday</td>\n",
       "      <td>wedding</td>\n",
       "      <td>dessert</td>\n",
       "      <td>view</td>\n",
       "      <td>beat</td>\n",
       "      <td>cookie</td>\n",
       "      <td>favorite</td>\n",
       "      <td>party</td>\n",
       "      <td>event</td>\n",
       "      <td>sister</td>\n",
       "      <td>include</td>\n",
       "      <td>bakery</td>\n",
       "      <td>pub</td>\n",
       "      <td>birthday food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 14</th>\n",
       "      <td>food</td>\n",
       "      <td>place</td>\n",
       "      <td>bar</td>\n",
       "      <td>beer</td>\n",
       "      <td>drink</td>\n",
       "      <td>night</td>\n",
       "      <td>service</td>\n",
       "      <td>time</td>\n",
       "      <td>selection</td>\n",
       "      <td>atmosphere</td>\n",
       "      <td>love</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>price</td>\n",
       "      <td>come</td>\n",
       "      <td>people</td>\n",
       "      <td>late night beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 15</th>\n",
       "      <td>order</td>\n",
       "      <td>wait</td>\n",
       "      <td>food</td>\n",
       "      <td>minute</td>\n",
       "      <td>table</td>\n",
       "      <td>come</td>\n",
       "      <td>service</td>\n",
       "      <td>time</td>\n",
       "      <td>ask</td>\n",
       "      <td>seat</td>\n",
       "      <td>waitress</td>\n",
       "      <td>say</td>\n",
       "      <td>server</td>\n",
       "      <td>sit</td>\n",
       "      <td>tell</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 16</th>\n",
       "      <td>tell</td>\n",
       "      <td>say</td>\n",
       "      <td>work</td>\n",
       "      <td>ask</td>\n",
       "      <td>customer</td>\n",
       "      <td>need</td>\n",
       "      <td>day</td>\n",
       "      <td>come</td>\n",
       "      <td>week</td>\n",
       "      <td>time</td>\n",
       "      <td>want</td>\n",
       "      <td>leave</td>\n",
       "      <td>know</td>\n",
       "      <td>phone</td>\n",
       "      <td>guy</td>\n",
       "      <td>customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 17</th>\n",
       "      <td>airport</td>\n",
       "      <td>car</td>\n",
       "      <td>parking</td>\n",
       "      <td>time</td>\n",
       "      <td>service</td>\n",
       "      <td>line</td>\n",
       "      <td>park</td>\n",
       "      <td>lot</td>\n",
       "      <td>drive</td>\n",
       "      <td>location</td>\n",
       "      <td>hour</td>\n",
       "      <td>people</td>\n",
       "      <td>wait</td>\n",
       "      <td>charge</td>\n",
       "      <td>use</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 18</th>\n",
       "      <td>include</td>\n",
       "      <td>fun</td>\n",
       "      <td>fan</td>\n",
       "      <td>spot</td>\n",
       "      <td>theater</td>\n",
       "      <td>cuisine</td>\n",
       "      <td>soul</td>\n",
       "      <td>heart</td>\n",
       "      <td>pass</td>\n",
       "      <td>weekend</td>\n",
       "      <td>course</td>\n",
       "      <td>seat</td>\n",
       "      <td>venue</td>\n",
       "      <td>remind</td>\n",
       "      <td>stuff</td>\n",
       "      <td>weekend food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 19</th>\n",
       "      <td>food</td>\n",
       "      <td>chicken</td>\n",
       "      <td>order</td>\n",
       "      <td>salad</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>sauce</td>\n",
       "      <td>meal</td>\n",
       "      <td>eat</td>\n",
       "      <td>lunch</td>\n",
       "      <td>dish</td>\n",
       "      <td>come</td>\n",
       "      <td>menu</td>\n",
       "      <td>taste</td>\n",
       "      <td>dinner</td>\n",
       "      <td>bread</td>\n",
       "      <td>american lunch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word 0     Word 1    Word 2     Word 3      Word 4    Word 5  \\\n",
       "Topic 0         price    service      make    quality         try     dress   \n",
       "Topic 1        burger        fry       bbq       gate  ingredient      ring   \n",
       "Topic 2         hotel       stay    flight       walk       night  downtown   \n",
       "Topic 3         spend      floor      card      offer        look       lot   \n",
       "Topic 4         store       shop       buy  selection        item       bed   \n",
       "Topic 5          hair      salon     color    picture        hate   stylist   \n",
       "Topic 6          room      staff      area   bathroom        work     class   \n",
       "Topic 7         place       time      make       know        love      year   \n",
       "Topic 8         pizza   sandwich    cheese      steak       order      beef   \n",
       "Topic 9   reservation     tomato      city     buffet        wrap     joint   \n",
       "Topic 10    breakfast        kid   pancake       ride         egg     level   \n",
       "Topic 11         food     salmon      star        fly     service     night   \n",
       "Topic 12       coffee        tea      love    seating       place       sub   \n",
       "Topic 13         cake  chocolate  birthday    wedding     dessert      view   \n",
       "Topic 14         food      place       bar       beer       drink     night   \n",
       "Topic 15        order       wait      food     minute       table      come   \n",
       "Topic 16         tell        say      work        ask    customer      need   \n",
       "Topic 17      airport        car   parking       time     service      line   \n",
       "Topic 18      include        fun       fan       spot     theater   cuisine   \n",
       "Topic 19         food    chicken     order      salad  restaurant     sauce   \n",
       "\n",
       "            Word 6      Word 7     Word 8      Word 9   Word 10     Word 11  \\\n",
       "Topic 0       wife      choose       wine       think     place        size   \n",
       "Topic 1       mert      spring      booth        taco  meatball        hope   \n",
       "Topic 2      place  restaurant     travel       check     chair      street   \n",
       "Topic 3      thing     variety      place      credit       bag      window   \n",
       "Topic 4   purchase     product       sale      market   section     grocery   \n",
       "Topic 5    haircut     receive   discover  experience    listen    elevator   \n",
       "Topic 6     center    location      water        pool   machine        desk   \n",
       "Topic 7        try        look       want        come       say        feel   \n",
       "Topic 8      place         eat        fry       slice     sauce       crust   \n",
       "Topic 9     pickle     lettuce  highlight   concourse   platter         pad   \n",
       "Topic 10      club        year     brunch        team       art       toast   \n",
       "Topic 11     movie         rib     dining       sushi     place        miss   \n",
       "Topic 12       cup      choice    layover         lot  starbuck        hang   \n",
       "Topic 13      beat      cookie   favorite       party     event      sister   \n",
       "Topic 14   service        time  selection  atmosphere      love  restaurant   \n",
       "Topic 15   service        time        ask        seat  waitress         say   \n",
       "Topic 16       day        come       week        time      want       leave   \n",
       "Topic 17      park         lot      drive    location      hour      people   \n",
       "Topic 18      soul       heart       pass     weekend    course        seat   \n",
       "Topic 19      meal         eat      lunch        dish      come        menu   \n",
       "\n",
       "           Word 12     Word 13   Word 14                Topics  \n",
       "Topic 0       look        menu    course                 price  \n",
       "Topic 1       pack        bone   weather                  meat  \n",
       "Topic 2   terminal      option  security              location  \n",
       "Topic 3     locate  appreciate     house                 money  \n",
       "Topic 4       book        help      need                  shop  \n",
       "Topic 5        com        band     reach            hair salon  \n",
       "Topic 6        use         day      stay            cleaniness  \n",
       "Topic 7      think      people     visit         communciation  \n",
       "Topic 8   delivery        meat      wing             fast food  \n",
       "Topic 9    mustard     stomach   weekend     american sandwich  \n",
       "Topic 10    museum    schedule     child    american breakfast  \n",
       "Topic 11       clt        girl      date         dinner plates  \n",
       "Topic 12  standard         lol     drink        morning drinks  \n",
       "Topic 13   include      bakery       pub         birthday food  \n",
       "Topic 14     price        come    people  late night beverages  \n",
       "Topic 15    server         sit      tell            restaurant  \n",
       "Topic 16      know       phone       guy      customer service  \n",
       "Topic 17      wait      charge       use              delivery  \n",
       "Topic 18     venue      remind     stuff          weekend food  \n",
       "Topic 19     taste      dinner     bread        american lunch  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document — Topic Matrix\n",
    "lda_output = lda_model.transform(data_vectorized)# column names\n",
    "topicnames = ['Topic' + str(i) for i in range(lda_model.n_components)]# index names\n",
    "docnames = ['Doc' + str(i) for i in range(len(data))]# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic# Styling\n",
    "def color_green(val):\n",
    " color = 'green' if val > .1 else 'black'\n",
    " return 'color: {col}'.format(col=color)\n",
    "def make_bold(val):\n",
    " weight = 700 if val > .1 else 400\n",
    " return 'font-weight: {weight}'.format(weight=weight)# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "\n",
    "# Topic-Keyword Matrix\n",
    "df_topic_keywords = pd.DataFrame(lda_model.components_)# Assign Column and Index\n",
    "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
    "df_topic_keywords.index = topicnames# View\n",
    "df_topic_keywords.head()\n",
    "\n",
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=15)# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "\n",
    "Topics = [\"price\",\"meat\",\"location\",\"money\",\"shop\", \n",
    "          \"hair salon\", \"cleaniness\", \"communciation\", \"fast food\", \"american sandwich\", \"american breakfast\", \"dinner plates\", \"morning drinks\", \"birthday food\", \"late night beverages\", \"restaurant\", \"customer service\", \"delivery\", \"weekend food\", \"american lunch\"]\n",
    "df_topic_keywords[\"Topics\"]=Topics\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'make', 'know', 'love', 'year', 'try', 'look', 'want', 'come', 'say', 'feel', 'think', 'people']\n",
      "communciation\n"
     ]
    }
   ],
   "source": [
    "# Define function to predict topic for a given text document.\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "def predict_topic(text, nlp=nlp):\n",
    "    global sent_to_words\n",
    "    global lemmatization# Step 1: Clean with simple_preprocess\n",
    "    mytext_2 = list(sent_to_words(text))# Step 2: Lemmatize\n",
    "    mytext_3 = lemmatization(mytext_2, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])# Step 3: Vectorize transform\n",
    "    mytext_4 = vectorizer.transform(mytext_3)# Step 4: LDA Transform\n",
    "    topic_probability_scores = lda_model.transform(mytext_4)\n",
    "    topic = df_topic_keywords.iloc[np.argmax(topic_probability_scores), 1:14].values.tolist()\n",
    "    \n",
    "    # Step 5: Infer Topic\n",
    "    infer_topic = df_topic_keywords.iloc[np.argmax(topic_probability_scores), -1]\n",
    "    \n",
    "    #topic_guess = df_topic_keywords.iloc[np.argmax(topic_probability_scores), Topics]\n",
    "    return infer_topic, topic, topic_probability_scores# Predict the topic\n",
    "mytext = [\"Very Useful in diabetes age 30. I need control sugar. thanks Good deal\"]\n",
    "infer_topic, topic, prob_scores = predict_topic(text = mytext)\n",
    "print(topic)\n",
    "print(infer_topic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Topic_key_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr Hoagie is an institution. Walking in, it do...</td>\n",
       "      <td>meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent food. Superb customer service. I mis...</td>\n",
       "      <td>dinner plates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes this place is a little out dated and not o...</td>\n",
       "      <td>communciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "      <td>fast food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We checked this place out this past Monday for...</td>\n",
       "      <td>fast food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27285</th>\n",
       "      <td>Ok I figured this would be ordinary diner food...</td>\n",
       "      <td>american breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27286</th>\n",
       "      <td>Love the food and the atmosphere. I eat here a...</td>\n",
       "      <td>customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27287</th>\n",
       "      <td>The service was nice, the front desk girls wer...</td>\n",
       "      <td>cleaniness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27288</th>\n",
       "      <td>Horrible showers, but nice folks.</td>\n",
       "      <td>cleaniness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27289</th>\n",
       "      <td>Stopped here on the way to Fort Jackson.  It's...</td>\n",
       "      <td>cleaniness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27290 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text      Topic_key_word\n",
       "0      Mr Hoagie is an institution. Walking in, it do...                meat\n",
       "1      Excellent food. Superb customer service. I mis...       dinner plates\n",
       "2      Yes this place is a little out dated and not o...       communciation\n",
       "3      All the food is great here. But the best thing...           fast food\n",
       "4      We checked this place out this past Monday for...           fast food\n",
       "...                                                  ...                 ...\n",
       "27285  Ok I figured this would be ordinary diner food...  american breakfast\n",
       "27286  Love the food and the atmosphere. I eat here a...    customer service\n",
       "27287  The service was nice, the front desk girls wer...          cleaniness\n",
       "27288                  Horrible showers, but nice folks.          cleaniness\n",
       "27289  Stopped here on the way to Fort Jackson.  It's...          cleaniness\n",
       "\n",
       "[27290 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_predict_topic(text):\n",
    " text = [text]\n",
    " infer_topic, topic, prob_scores = predict_topic(text = text)\n",
    " return(infer_topic)\n",
    "df[\"Topic_key_word\"]= df['text'].apply(apply_predict_topic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
